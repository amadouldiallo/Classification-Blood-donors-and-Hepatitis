{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24975f59",
   "metadata": {},
   "source": [
    "**MACHINE LEARNING WITH PYSPARK**\n",
    "+ USING DATABRICK TOOL\n",
    "+ https://community.cloud.databricks.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f4fef6",
   "metadata": {},
   "source": [
    "\n",
    "#### Check if patient is **Hep** or No based on parameters\n",
    "\n",
    "##### ML with pyspark\n",
    "+ Classify predict\n",
    "\n",
    "###### Datasource\n",
    "+ **[Data Set link](https://archive.ics.uci.edu/ml/datasets/HCV+data)**\n",
    "\n",
    "####### Abstract\n",
    "+ **The data set contains laboratory values of blood donors and Hepatitis C patients and demographic values like age**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf163bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0841b02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-11 23:22:30 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = spark = SparkSession.builder.appName('ML_With_Spark').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97e325ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://air-de-amadou:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ML_With_Spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f7ed028a550>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0eac8b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"ERROR\") #ALL, DEBUG, ERROR, FATAL, INFO, OFF, TRACE, WARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bfe2698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching Java Virtual Machines (2):\r\n",
      "    18.0.1 (x86_64) \"Oracle Corporation\" - \"OpenJDK 18.0.1\" /Users/amadoudiallo/Library/Java/JavaVirtualMachines/openjdk-18.0.1/Contents/Home\r\n",
      "    1.8.0_292 (x86_64) \"AdoptOpenJDK\" - \"AdoptOpenJDK 8\" /Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home\r\n",
      "/Users/amadoudiallo/Library/Java/JavaVirtualMachines/openjdk-18.0.1/Contents/Home\r\n"
     ]
    }
   ],
   "source": [
    "! /usr/libexec/java_home -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f77a90fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read data from filestore of databricks\n",
    "\n",
    "df = spark.read.csv(path=r\"./data/hcv.csv\", inferSchema=True, header=True)\n",
    "#df = spark.read.csv('data/hcv.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cbc008df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+---+---+----+----+----+----+----+-----+----+-----+----+----+\n",
      "|_c0|     Category|Age|Sex| ALB| ALP| ALT| AST| BIL|  CHE|CHOL| CREA| GGT|PROT|\n",
      "+---+-------------+---+---+----+----+----+----+----+-----+----+-----+----+----+\n",
      "|  1|0=Blood Donor| 32|  m|38.5|52.5| 7.7|22.1| 7.5| 6.93|3.23|106.0|12.1|  69|\n",
      "|  2|0=Blood Donor| 32|  m|38.5|70.3|  18|24.7| 3.9|11.17| 4.8| 74.0|15.6|76.5|\n",
      "|  3|0=Blood Donor| 32|  m|46.9|74.7|36.2|52.6| 6.1| 8.84| 5.2| 86.0|33.2|79.3|\n",
      "|  4|0=Blood Donor| 32|  m|43.2|  52|30.6|22.6|18.9| 7.33|4.74| 80.0|33.8|75.7|\n",
      "|  5|0=Blood Donor| 32|  m|39.2|74.1|32.6|24.8| 9.6| 9.15|4.32| 76.0|29.9|68.7|\n",
      "|  6|0=Blood Donor| 32|  m|41.6|43.3|18.5|19.7|12.3| 9.92|6.05|111.0|91.0|  74|\n",
      "+---+-------------+---+---+----+----+----+----+----+-----+----+-----+----+----+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c40a7b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_c0', 'Category', 'Age', 'Sex', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT']\n"
     ]
    }
   ],
   "source": [
    "# columns \n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4bda19b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange columns by putting category as last columns (it is the target to predict)\n",
    "df = df.select('Age', 'Sex', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT', 'Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "114642b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+----+----+----+----+-----+----+-----+----+----+-------------+\n",
      "|Age|Sex| ALB| ALP| ALT| AST| BIL|  CHE|CHOL| CREA| GGT|PROT|     Category|\n",
      "+---+---+----+----+----+----+----+-----+----+-----+----+----+-------------+\n",
      "| 32|  m|38.5|52.5| 7.7|22.1| 7.5| 6.93|3.23|106.0|12.1|  69|0=Blood Donor|\n",
      "| 32|  m|38.5|70.3|  18|24.7| 3.9|11.17| 4.8| 74.0|15.6|76.5|0=Blood Donor|\n",
      "| 32|  m|46.9|74.7|36.2|52.6| 6.1| 8.84| 5.2| 86.0|33.2|79.3|0=Blood Donor|\n",
      "| 32|  m|43.2|  52|30.6|22.6|18.9| 7.33|4.74| 80.0|33.8|75.7|0=Blood Donor|\n",
      "| 32|  m|39.2|74.1|32.6|24.8| 9.6| 9.15|4.32| 76.0|29.9|68.7|0=Blood Donor|\n",
      "+---+---+----+----+----+----+----+-----+----+-----+----+----+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the rearrangement\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "412c57fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Age', 'int'),\n",
       " ('Sex', 'string'),\n",
       " ('ALB', 'string'),\n",
       " ('ALP', 'string'),\n",
       " ('ALT', 'string'),\n",
       " ('AST', 'double'),\n",
       " ('BIL', 'double'),\n",
       " ('CHE', 'double'),\n",
       " ('CHOL', 'string'),\n",
       " ('CREA', 'double'),\n",
       " ('GGT', 'double'),\n",
       " ('PROT', 'string'),\n",
       " ('Category', 'string')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check types\n",
    "# Before inferSchema = True\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4dea46ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- ALB: string (nullable = true)\n",
      " |-- ALP: string (nullable = true)\n",
      " |-- ALT: string (nullable = true)\n",
      " |-- AST: double (nullable = true)\n",
      " |-- BIL: double (nullable = true)\n",
      " |-- CHE: double (nullable = true)\n",
      " |-- CHOL: string (nullable = true)\n",
      " |-- CREA: double (nullable = true)\n",
      " |-- GGT: double (nullable = true)\n",
      " |-- PROT: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check for Schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "02c1bae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+----+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+-----------------+-----------------+-------------+\n",
      "|summary|               Age| Sex|              ALB|               ALP|               ALT|              AST|               BIL|               CHE|              CHOL|             CREA|              GGT|             PROT|     Category|\n",
      "+-------+------------------+----+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+-----------------+-----------------+-------------+\n",
      "|  count|               615| 615|              615|               615|               615|              615|               615|               615|               615|              615|              615|              615|          615|\n",
      "|   mean| 47.40813008130081|null|41.62019543973941| 68.28391959798999| 28.45081433224754|34.78634146341462|11.396747967479675| 8.196634146341458| 5.368099173553719|81.28780487804877|39.53317073170732|72.04413680781768|         null|\n",
      "| stddev|10.055105445519239|null|5.780629404103076|26.028315300123676|25.469688813870942|33.09069033855156|19.673149805846588|2.2056572704292927|1.1327284311597354|49.75616601234976|54.66107123891245|5.402635737104955|         null|\n",
      "|    min|                19|   f|             14.9|             100.4|               0.9|             10.6|               0.8|              1.42|              1.43|              8.0|              4.5|             44.8|0=Blood Donor|\n",
      "|    max|                77|   m|               NA|                NA|                NA|            324.0|             254.0|             16.41|                NA|           1079.1|            650.9|               NA|  3=Cirrhosis|\n",
      "+-------+------------------+----+-----------------+------------------+------------------+-----------------+------------------+------------------+------------------+-----------------+-----------------+-----------------+-------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# description summary\n",
    "print(df.describe().show())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b8f131",
   "metadata": {},
   "source": [
    "**Check balance using value count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6e1e8779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            Category|count|\n",
      "+--------------------+-----+\n",
      "|       0=Blood Donor|  533|\n",
      "|         3=Cirrhosis|   30|\n",
      "|          2=Fibrosis|   21|\n",
      "|0s=suspect Blood ...|    7|\n",
      "|         1=Hepatitis|   24|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('Category').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a7f429",
   "metadata": {},
   "source": [
    "**Feature engineering**\n",
    "+ Numerical values\n",
    "+ Vectorization\n",
    "+ Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7a359d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+----+----+----+----+-----+----+-----+----+----+-------------+\n",
      "|Age|Sex| ALB| ALP| ALT| AST| BIL|  CHE|CHOL| CREA| GGT|PROT|     Category|\n",
      "+---+---+----+----+----+----+----+-----+----+-----+----+----+-------------+\n",
      "| 32|  m|38.5|52.5| 7.7|22.1| 7.5| 6.93|3.23|106.0|12.1|  69|0=Blood Donor|\n",
      "| 32|  m|38.5|70.3|  18|24.7| 3.9|11.17| 4.8| 74.0|15.6|76.5|0=Blood Donor|\n",
      "| 32|  m|46.9|74.7|36.2|52.6| 6.1| 8.84| 5.2| 86.0|33.2|79.3|0=Blood Donor|\n",
      "| 32|  m|43.2|  52|30.6|22.6|18.9| 7.33|4.74| 80.0|33.8|75.7|0=Blood Donor|\n",
      "| 32|  m|39.2|74.1|32.6|24.8| 9.6| 9.15|4.32| 76.0|29.9|68.7|0=Blood Donor|\n",
      "+---+---+----+----+----+----+----+-----+----+-----+----+----+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369244c6",
   "metadata": {},
   "source": [
    "**For feature enginneering, we use the ml package of pyspark for vectorization, building model, and evaluation..**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ddb91e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import ML package\n",
    "import pyspark.ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aa6b1409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Estimator',\n",
       " 'Model',\n",
       " 'Pipeline',\n",
       " 'PipelineModel',\n",
       " 'Transformer',\n",
       " 'UnaryTransformer',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'base',\n",
       " 'classification',\n",
       " 'clustering',\n",
       " 'common',\n",
       " 'evaluation',\n",
       " 'feature',\n",
       " 'fpm',\n",
       " 'image',\n",
       " 'linalg',\n",
       " 'param',\n",
       " 'pipeline',\n",
       " 'recommendation',\n",
       " 'regression',\n",
       " 'stat',\n",
       " 'tuning',\n",
       " 'util',\n",
       " 'wrapper']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(pyspark.ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d409cc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|Sex|\n",
      "+---+\n",
      "|  m|\n",
      "|  f|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Unique values for sex\n",
    "df.select('Sex').distinct().show() # we have two distinct value for sex .. 'm' as male and 'f' as female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9c5c02b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd7cc4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert this column into Numerical value\n",
    "## label encoding (0 or 1 of value Sex column)\n",
    "\n",
    "genderEncoder = StringIndexer(inputCol='Sex', outputCol= 'Gender').fit(df) # we use Sex column to generate Gender column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "36a7096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = genderEncoder.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5904f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Category column\n",
    "## label encoding\n",
    "catEncoder = StringIndexer(inputCol='Category', outputCol='Target').fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e4b74a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = catEncoder.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9eb53bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+----+----+----+---+-----+----+-----+----+----+-------------+------+------+\n",
      "|Age|Sex| ALB| ALP| ALT| AST|BIL|  CHE|CHOL| CREA| GGT|PROT|     Category|Gender|Target|\n",
      "+---+---+----+----+----+----+---+-----+----+-----+----+----+-------------+------+------+\n",
      "| 32|  m|38.5|52.5| 7.7|22.1|7.5| 6.93|3.23|106.0|12.1|  69|0=Blood Donor|   0.0|   0.0|\n",
      "| 32|  m|38.5|70.3|  18|24.7|3.9|11.17| 4.8| 74.0|15.6|76.5|0=Blood Donor|   0.0|   0.0|\n",
      "| 32|  m|46.9|74.7|36.2|52.6|6.1| 8.84| 5.2| 86.0|33.2|79.3|0=Blood Donor|   0.0|   0.0|\n",
      "+---+---+----+----+----+----+---+-----+----+-----+----+----+-------------+------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d9398a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- ALB: string (nullable = true)\n",
      " |-- ALP: string (nullable = true)\n",
      " |-- ALT: string (nullable = true)\n",
      " |-- AST: double (nullable = true)\n",
      " |-- BIL: double (nullable = true)\n",
      " |-- CHE: double (nullable = true)\n",
      " |-- CHOL: string (nullable = true)\n",
      " |-- CREA: double (nullable = true)\n",
      " |-- GGT: double (nullable = true)\n",
      " |-- PROT: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Gender: double (nullable = false)\n",
      " |-- Target: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd0fda36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0=Blood Donor',\n",
       " '3=Cirrhosis',\n",
       " '1=Hepatitis',\n",
       " '2=Fibrosis',\n",
       " '0s=suspect Blood Donor']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catEncoder.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "728324b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IndexToString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9be03fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = IndexToString(inputCol='Target', outputCol='orig_cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f72cdd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## go back ..return original column\n",
    "converted_df = converter.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "25545555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+----+----+----+----+-----+----+-----+----+----+-------------+------+------+-------------+\n",
      "|Age|Sex| ALB| ALP| ALT| AST| BIL|  CHE|CHOL| CREA| GGT|PROT|     Category|Gender|Target|     orig_cat|\n",
      "+---+---+----+----+----+----+----+-----+----+-----+----+----+-------------+------+------+-------------+\n",
      "| 32|  m|38.5|52.5| 7.7|22.1| 7.5| 6.93|3.23|106.0|12.1|  69|0=Blood Donor|   0.0|   0.0|0=Blood Donor|\n",
      "| 32|  m|38.5|70.3|  18|24.7| 3.9|11.17| 4.8| 74.0|15.6|76.5|0=Blood Donor|   0.0|   0.0|0=Blood Donor|\n",
      "| 32|  m|46.9|74.7|36.2|52.6| 6.1| 8.84| 5.2| 86.0|33.2|79.3|0=Blood Donor|   0.0|   0.0|0=Blood Donor|\n",
      "| 32|  m|43.2|  52|30.6|22.6|18.9| 7.33|4.74| 80.0|33.8|75.7|0=Blood Donor|   0.0|   0.0|0=Blood Donor|\n",
      "+---+---+----+----+----+----+----+-----+----+-----+----+----+-------------+------+------+-------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "converted_df.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473c572b",
   "metadata": {},
   "source": [
    "**Feature** \n",
    "+ Selection numerical column and drop string column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0bc626e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Sex', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT', 'Category', 'Gender', 'Target']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b5fdcd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.select('Age', 'Gender', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT', 'Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a54ef23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.toPandas().replace('NA', 0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9bbbdd17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d002a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert df2 (pandas to spark dataframe)\n",
    "new_df = spark.createDataFrame(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "92d85c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: double (nullable = true)\n",
      " |-- Gender: double (nullable = true)\n",
      " |-- ALB: double (nullable = true)\n",
      " |-- ALP: double (nullable = true)\n",
      " |-- ALT: double (nullable = true)\n",
      " |-- AST: double (nullable = true)\n",
      " |-- BIL: double (nullable = true)\n",
      " |-- CHE: double (nullable = true)\n",
      " |-- CHOL: double (nullable = true)\n",
      " |-- CREA: double (nullable = true)\n",
      " |-- GGT: double (nullable = true)\n",
      " |-- PROT: double (nullable = true)\n",
      " |-- Target: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e2e47df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## required columns\n",
    "\n",
    "required_columns = ['Age', 'Gender', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT', 'Target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dafa6fd",
   "metadata": {},
   "source": [
    "+ Vectorization columns\n",
    "\n",
    "VectorAssembler is a transformer that combines a given list of columns into a single vector column. It is useful for combining raw features and features generated by different feature transformers into a single feature vector, in order to train ML models like logistic regression and decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "59c7c7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_assembler = VectorAssembler(inputCols=required_columns, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7a17d9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = vect_assembler.transform(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "775e1ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+----+----+----+----+----+-----+----+-----+----+----+------+--------------------+\n",
      "| Age|Gender| ALB| ALP| ALT| AST| BIL|  CHE|CHOL| CREA| GGT|PROT|Target|            features|\n",
      "+----+------+----+----+----+----+----+-----+----+-----+----+----+------+--------------------+\n",
      "|32.0|   0.0|38.5|52.5| 7.7|22.1| 7.5| 6.93|3.23|106.0|12.1|69.0|   0.0|[32.0,0.0,38.5,52...|\n",
      "|32.0|   0.0|38.5|70.3|18.0|24.7| 3.9|11.17| 4.8| 74.0|15.6|76.5|   0.0|[32.0,0.0,38.5,70...|\n",
      "|32.0|   0.0|46.9|74.7|36.2|52.6| 6.1| 8.84| 5.2| 86.0|33.2|79.3|   0.0|[32.0,0.0,46.9,74...|\n",
      "|32.0|   0.0|43.2|52.0|30.6|22.6|18.9| 7.33|4.74| 80.0|33.8|75.7|   0.0|[32.0,0.0,43.2,52...|\n",
      "|32.0|   0.0|39.2|74.1|32.6|24.8| 9.6| 9.15|4.32| 76.0|29.9|68.7|   0.0|[32.0,0.0,39.2,74...|\n",
      "+----+------+----+----+----+----+----+-----+----+-----+----+----+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e71e65",
   "metadata": {},
   "source": [
    "### Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "140352eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = new_df.randomSplit([0.7, 0.3],seed=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11184d70",
   "metadata": {},
   "source": [
    "### Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ac57e3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression, DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ba93d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### logistic model\n",
    "\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='Target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c44e13",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6bf4e335",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e514ce57",
   "metadata": {},
   "source": [
    "### Prediction on test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "288df518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+----+----+----+----+----+-----+----+-----+----+----+------+--------------------+--------------------+--------------------+----------+\n",
      "| Age|Gender| ALB| ALP| ALT| AST| BIL|  CHE|CHOL| CREA| GGT|PROT|Target|            features|       rawPrediction|         probability|prediction|\n",
      "+----+------+----+----+----+----+----+-----+----+-----+----+----+------+--------------------+--------------------+--------------------+----------+\n",
      "|32.0|   0.0|42.2|41.9|35.8|31.1|16.1| 5.82| 4.6|109.0|21.5|67.1|   0.0|[32.0,0.0,42.2,41...|[391.169028224589...|[1.0,6.6809237325...|       0.0|\n",
      "|33.0|   0.0|36.3|78.6|23.6|22.0| 7.0| 8.56|5.38| 78.0|19.4|68.7|   0.0|[33.0,0.0,36.3,78...|[501.959256810496...|[1.0,1.1031498125...|       0.0|\n",
      "|33.0|   0.0|36.6|57.1|38.9|40.3|24.9| 9.62| 5.5|112.0|27.6|69.3|   0.0|[33.0,0.0,36.6,57...|[402.124713027645...|[1.0,4.9572075156...|       0.0|\n",
      "|33.0|   0.0|38.7|39.8|22.5|23.0| 4.1| 4.63|4.97| 63.0|15.2|71.9|   0.0|[33.0,0.0,38.7,39...|[411.884692528756...|[1.0,2.6310159611...|       0.0|\n",
      "|33.0|   0.0|45.2|88.3|32.4|31.2|10.1| 9.78|5.51|102.0|48.5|76.5|   0.0|[33.0,0.0,45.2,88...|[526.735040008043...|[1.0,5.2563173708...|       0.0|\n",
      "|34.0|   0.0|40.5|32.4|29.6|27.1| 5.8| 10.5|4.56| 91.0|26.6|72.0|   0.0|[34.0,0.0,40.5,32...|[453.389430737212...|[1.0,8.7275314142...|       0.0|\n",
      "|34.0|   0.0|46.8|61.7|24.5|24.2|23.1|10.99| 4.6| 83.0|23.8|73.1|   0.0|[34.0,0.0,46.8,61...|[493.726503831349...|[1.0,9.5701594837...|       0.0|\n",
      "|35.0|   0.0|37.5|69.8|37.1|25.0| 7.8|11.66|5.73| 84.0|27.3|71.0|   0.0|[35.0,0.0,37.5,69...|[530.784079956260...|[1.0,1.4705777321...|       0.0|\n",
      "|35.0|   0.0|44.5|70.3|26.2|25.1| 5.1|10.12|4.69| 82.0|20.7|67.2|   0.0|[35.0,0.0,44.5,70...|[543.287202308801...|[1.0,2.6136571724...|       0.0|\n",
      "|35.0|   0.0|48.7|72.7|24.1|31.0|45.1|  9.4| 3.8| 90.0|20.0|75.8|   0.0|[35.0,0.0,48.7,72...|[410.457035325134...|[1.0,2.1332325291...|       0.0|\n",
      "+----+------+----+----+----+----+----+-----+----+-----+----+----+------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Prediction\n",
    "\n",
    "y_pred = lr_model.transform(test_df)\n",
    "y_pred.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b8bdd189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Age', 'Gender', 'ALB', 'ALP', 'ALT', 'AST', 'BIL', 'CHE', 'CHOL', 'CREA', 'GGT', 'PROT', 'Target', 'features', 'rawPrediction', 'probability', 'prediction']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3a212e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+----------+\n",
      "|Target|       rawPrediction|         probability|prediction|\n",
      "+------+--------------------+--------------------+----------+\n",
      "|   0.0|[391.169028224589...|[1.0,6.6809237325...|       0.0|\n",
      "|   0.0|[501.959256810496...|[1.0,1.1031498125...|       0.0|\n",
      "|   0.0|[402.124713027645...|[1.0,4.9572075156...|       0.0|\n",
      "|   0.0|[411.884692528756...|[1.0,2.6310159611...|       0.0|\n",
      "|   0.0|[526.735040008043...|[1.0,5.2563173708...|       0.0|\n",
      "|   0.0|[453.389430737212...|[1.0,8.7275314142...|       0.0|\n",
      "|   0.0|[493.726503831349...|[1.0,9.5701594837...|       0.0|\n",
      "|   0.0|[530.784079956260...|[1.0,1.4705777321...|       0.0|\n",
      "|   0.0|[543.287202308801...|[1.0,2.6136571724...|       0.0|\n",
      "|   0.0|[410.457035325134...|[1.0,2.1332325291...|       0.0|\n",
      "+------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred.select('Target','rawPrediction', 'probability', 'prediction').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985163a1",
   "metadata": {},
   "source": [
    "### Evaluate my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e9825cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "multi_evaluator = MulticlassClassificationEvaluator(labelCol='Target', metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6bb12c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9774011299435028"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_evaluator.evaluate(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2418edf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "lr_metrics = MulticlassMetrics(y_pred['Target','prediction'].rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2573dee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9774011299435028\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy\", lr_metrics.accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cef2e0",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7daf9207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7adf0461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b80b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'lr_model.sav'\n",
    "pickle.dump(lr_model, open(\"models/\"+filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c59316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
